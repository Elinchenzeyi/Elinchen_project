# Results (With Some Graphs)

From the data section, I generated the train and test data, and the two different 
models are based on the data.

I could tell that speaking of the model performance comparison:
Random Forest	 vs. Linear Regression
Mean Squared Residuals for random forest:	11.5135.
Mean Squared Residuals for linear regression: tendency to be higher

% Variance Explained for random forest:	85.9%	
% Variance Explained for linear regression: tendency to be lower

Linearity Assumed for random forest? No
Linearity Assumed for linear regression?	Yes	

Captures Interactions for random forest?	Yes	
Captures Interactions for linear regression? No

Captures Non-linearity for random forest?	Yes	
Captures Non-linearity for linear regression? No





```{r}
library(randomForest)
library(MASS)
library(randomForest)
library(lime)
library(tidyverse)
library(caret)

data("Boston")
X <- Boston %>% select(-medv)
y <- Boston$medv

set.seed(42)
train_index <- createDataPartition(y, p = 0.8, list = FALSE)
X_train <- X[train_index, ]
y_train <- y[train_index]
X_test <- X[-train_index, ]
y_test <- y[-train_index]

rf_model <- randomForest(X_train, y_train, ntree = 500)
lm_model <- lm(medv ~ ., data = Boston[train_index, ])
rf_model
lm_model
```





After knowing about the model differences, it is essential to check for 
consistency in features for the SHAP random forest model for Boston
housing dataset. 





```{r}
library(fastshap)  # For fast SHAP approximations
library(randomForest)
library(dplyr)
library(FNN)
library(ggplot2)

data(Boston)
X <- Boston %>% select(-medv)
y <- Boston$medv

set.seed(42)
train_idx <- sample(seq_len(nrow(X)), size = 0.8 * nrow(X))
X_train <- X[train_idx, ]
y_train <- y[train_idx]
X_test <- X[-train_idx, ]
y_test <- y[-train_idx]

# Train the Random Forest model
rf_model <- randomForest(X_train, y_train, ntree = 500)

pred_fun <- function(model, newdata) predict(model, newdata = newdata)

shap_values <- fastshap::explain(
  rf_model,
  X = X_train,
  pred_wrapper = pred_fun,
  nsim = 50
)

k <- 5
knn_indices <- FNN::knnx.index(
  data = X_train,
  query = X_test,
  k = k
)

shap_diffs <- sapply(1:nrow(X_test), function(i) {
  test_shap <- shap_values[i, ]
  knn_shap <- colMeans(shap_values[knn_indices[i, ], ])  
  abs(test_shap - knn_shap)  
})

avg_shap_diffs <- rowMeans(shap_diffs)

avg_shap_diffs
```





We could interpret from the data that the average SHAP differences is low
for the features like:
-crim, -zn, -indus, -chas, -age, -dis, -rad, -tax, -ptratio, -black.

However, there is a high average differences for the features:
-rm, -lstat, -nox

Here, I made a PDP and ICE plot for knowing the reasons like why some features
were not consistent: 




```{r}
library(pdp)
library(ggplot2)

# Partial Dependence Plot
pdp_lstat <- partial(rf_model, pred.var = "lstat", train = X_train)
ggplot(pdp_lstat, aes(lstat, yhat)) + 
  geom_line() +
  labs(title = "Partial Dependence of 'lstat' on Price")

# ICE Plots
ice_lstat <- partial(rf_model, pred.var = "lstat", train = X_train, ice = TRUE)
ggplot(ice_lstat, aes(lstat, yhat, group = yhat.id)) + 
  geom_line(alpha = 0.2) +
  labs(title = "ICE Plots for 'lstat'")
```




From the graphs, I could notice that the trend of the curves show similar 
pattern, which is that as the number of the lower percentage of the population 
increases, the house price decreases significantly. 

The pdp is non-linear and drops significantly within the 0-10 range for lstat,
which implies that the house price is highly sensitive to lstat. 

Since the high inconsistency and non-linearity appear for the feature lstat,
I made the graph for the rm+ lstat for knowing if lstat has an interaction with 
rm that causes the SHAP's explanation to be inconsistent. 




```{r}
library(fastshap)
shap_values <- explain(rf_model, X = X_train, nsim = 50, pred_wrapper = pred_fun)

shap_values <- fastshap::explain(
  rf_model, 
  X = X_train, 
  pred_wrapper = pred_fun, 
  nsim = 50
)

shap_df <- as.data.frame(shap_values)
shap_df$lstat <- X_train$lstat  
shap_df$crim <- X_train$crim    

library(ggplot2)
ggplot(shap_df, aes(lstat, lstat, color = crim)) +
  geom_point(alpha = 0.5) +
  scale_color_gradient(low = "blue", high = "red") +
  labs(
    title = "SHAP Values for 'lstat' (Colored by Crime Rate)",
    x = "lstat (Actual Value)",
    y = "SHAP Value (Impact on Price)"
  )

```




I think from the graph above, it shows that the lstat and crim together give
a strong impact on the SHAP value (House price). Therefore, it explains for
why there is a high inconsistency for the lstat feature itself. Similarly, 
I think the high inconsistency for nox and rm could also be influenced by the 
interaction effects. 


Then, I explore the feature significance in linear regression model, and notice
that chas is the feature with no sigificance. I think it could tell that 
the p-value for chas is larger than the standard threshold, 0.05. But again, I 
believe it is still an important feature, especially for understanding if it
has an interaction effect or it might has the coefficient value. 




```{r}
library(fastshap)
library(shapviz)
library(ggplot2)
library(MASS)
library(randomForest)
library(lime)
library(tidyverse)
library(caret)
library(broom)
train_idx <- sample(1:nrow(Boston), 0.8 * nrow(Boston))
train_data <- Boston[train_idx, ]
test_data <- Boston[-train_idx, ]

predict_rf <- function(model, newdata) {
  predict(model, newdata = newdata)
}

shap_values <- fastshap::explain(
  rf_model,
  X = test_data[1:5, -which(names(test_data) == "medv")],  
  pred_wrapper = predict_rf,
  nsim = 100
)

dim(shap_values) 
dim(test_data[1:5, -which(names(test_data) == "medv")]) 

cases_to_plot <- 1:5
shp <- shapviz(
  object = shap_values[cases_to_plot, ], 
  X = test_data[cases_to_plot, -which(names(test_data) == "medv")]
)



data(Boston)


set.seed(42)
train_idx <- sample(1:nrow(Boston), 0.8 * nrow(Boston))
train_data <- Boston[train_idx, ]
test_data <- Boston[-train_idx, ]


lm_model <- lm(medv ~ ., data = train_data)

lm_coef <- tidy(lm_model) %>%
  mutate(
    abs_effect = abs(estimate), 
    significance = ifelse(p.value < 0.05, "Significant", "Not significant")
  )


lm_coef %>%
  filter(term != "(Intercept)") %>%
  arrange(desc(abs_effect))

```





Then, I did a visual comparison graph that is also shown in the graphs.qmd. 
It is the comparison graph that we can easily detect that SHAP highlights some 
important features that might not count as important in the linear regression
model. Similarly, linear regression has some features that are not count
important in the SHAP random forest model. 

However, there is still a strong alignment for multiple features in
linear regression model and SHAP's random forest model. More details will
be explained later in the graphs and analysis section!




```{r}
library(plotly)
library(shiny)
library(ggplot2)
library(tidyverse)

shap_values_df <- as.data.frame(shap_values)

shap_importance <- colMeans(abs(shap_values_df))

importance_df <- data.frame(
  Feature = names(shap_importance),
  Importance = shap_importance
)

shap_df <- data.frame(
  Feature = names(shap_importance),
  Importance = shap_importance,
  Model = "Random Forest (SHAP)"
)

library(broom)


lm_model <- lm(medv ~ ., data = train_data)

lm_coef <- tidy(lm_model) %>%
  filter(term != "(Intercept)") %>%
  mutate(
    Feature = term,
    Importance = abs(estimate),
    Model = "Linear Regression"
  ) %>%
  select(Feature, Importance, Model)

combined_df <- bind_rows(shap_df, lm_coef)

library(ggplot2)

ggplot(combined_df, aes(x = reorder(Feature, Importance), y = Importance, fill = Model)) +
  geom_bar(stat = "identity", position = "dodge") +
  coord_flip() +
  labs(
    title = "Feature Importance: SHAP vs Linear Regression",
    x = "Feature",
    y = "Importance (Mean SHAP)",
    fill = "Model"
  ) +
  theme_minimal()

```

